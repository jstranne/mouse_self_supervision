{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Jason Stranne\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from RP_Downstream_Trainer import DownstreamNet, Downstream_Dataset, print_class_counts, num_correct, reduce_dataset_size\n",
    "from RP_Downstream_Trainer import smallest_class_len, restrict_training_size_per_class, train_end_to_end\n",
    "sys.path.insert(0, '..')\n",
    "from Stager_net_pratice import StagerNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Processing MouseCKA1_030515_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKA1_030615_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKL1_062514_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKB9_022715_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKB9_022815_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKL7_063014_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKL5_063014_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKL5_070114_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "Processing MouseCKL7_070114_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "dataset len is 360\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"Mouse_Training_Data\", \"Windowed_Data\", \"\")\n",
    "datasets_list=[]\n",
    "print('Loading Data')\n",
    "f=open(os.path.join(\"training_names.txt\"),'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    recordName=line.strip()\n",
    "    print('Processing', recordName)\n",
    "    data_file=root+recordName+os.sep+recordName\n",
    "    datasets_list.append(Downstream_Dataset(path=data_file))\n",
    "    d = Downstream_Dataset(path=data_file)\n",
    "    print(d.labels.shape)\n",
    "f.close()\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset(datasets_list)\n",
    "data_len = len(dataset)\n",
    "print(\"dataset len is\", len(dataset))\n",
    "\n",
    "train_len = int(data_len*0.6)\n",
    "val_len = data_len - train_len\n",
    "\n",
    "training_set, validation_set = torch.utils.data.random_split(dataset, [train_len, val_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f9bbe1d8a10>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "57\n",
      "50\n",
      "109\n",
      "[1, 10, None]\n"
     ]
    }
   ],
   "source": [
    "smallest_class = smallest_class_len(training_set, 3)\n",
    "num_samples=[]\n",
    "temp=1\n",
    "while temp < smallest_class:\n",
    "    num_samples.append(temp)\n",
    "    temp*=10\n",
    "num_samples.append(None)\n",
    "print(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_classes(model_path, tset, vset, epochs, sample_list):\n",
    "    outList=[]\n",
    "    for i in sample_list:\n",
    "        print(i)\n",
    "        outList.append(train_end_to_end(model_path, tset, vset, i, epochs, 3))\n",
    "        print(outList)\n",
    "    return outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666]\n",
      "10\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888]\n",
      "None\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888, 0.8611111111111112]\n"
     ]
    }
   ],
   "source": [
    "RP_vals = train_different_classes(\"RP_stagernet.pth\", training_set, validation_set, 100, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5416666666666666, 0.8263888888888888, 0.8611111111111112]\n"
     ]
    }
   ],
   "source": [
    "print(RP_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Processing MouseCKA1_030515_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKA1_030615_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKL1_062514_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKB9_022715_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKB9_022815_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKL7_063014_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKL5_063014_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKL5_070114_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "Processing MouseCKL7_070114_HCOFTS\n",
      "labels shape (40,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "data shape (40, 3000, 16)\n",
      "removed 0 unknown entries\n",
      "(40,)\n",
      "(40, 3000, 16)\n",
      "(360, 3000, 16)\n",
      "(360,)\n",
      "(360,)\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"Mouse_Training_Data\", \"Windowed_Data\", \"\")\n",
    "datasets_list=[]\n",
    "print('Loading Data')\n",
    "f=open(os.path.join(\"training_names.txt\"),'r')\n",
    "lines = f.readlines()\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "groups = []\n",
    "index = 0\n",
    "for line in lines:\n",
    "    recordName=line.strip()\n",
    "    print('Processing', recordName)\n",
    "    data_file=root+recordName+os.sep+recordName\n",
    "    d = Downstream_Dataset(path=data_file)\n",
    "    print(d.labels.shape)\n",
    "    print(d.data.shape)\n",
    "    x_vals.append(d.data)\n",
    "    y_vals.append(d.labels)\n",
    "    groups.append(np.ones(len(d.labels))*index)\n",
    "    index+=1\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n",
    "x_vals = np.vstack(x_vals)\n",
    "y_vals = np.concatenate(y_vals, axis=0)\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "print(x_vals.shape)\n",
    "print(y_vals.shape)\n",
    "print(group.shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(x_vals, y_vals, groups)\n",
    "\n",
    "\n",
    "for train_index, test_index in logo.split(x_vals, y_vals, groups):\n",
    "    from torch import Tensor\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    training_set = TensorDataset(Tensor(x_vals[train_index]), Tensor(y_vals[train_index]))\n",
    "    validation_set = TensorDataset(Tensor(x_vals[test_index]), Tensor(y_vals[test_index]))\n",
    "    print(len(training_set))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
