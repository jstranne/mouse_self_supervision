{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Jason Stranne\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from RP_Downstream_Trainer import DownstreamNet, Downstream_Dataset, print_class_counts, num_correct, reduce_dataset_size\n",
    "from RP_Downstream_Trainer import smallest_class_len, restrict_training_size_per_class, train_end_to_end\n",
    "sys.path.insert(0, '..')\n",
    "from Stager_net_pratice import StagerNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GroupKFold\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_classes(model_path, tset, vset, epochs, sample_list):\n",
    "    outList=[]\n",
    "    balanced_acc_out=[]\n",
    "    for i in sample_list:\n",
    "        # print(i)\n",
    "        acc, balanced_acc = train_end_to_end(model_path, tset, vset, i, epochs, 3)\n",
    "        outList.append(acc)\n",
    "        balanced_acc_out.append(balanced_acc)\n",
    "    return outList, balanced_acc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Processing MouseCKA1_030515_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKB9_022715_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL1_062514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL5_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL7_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN1_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN2_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN3_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO1_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO2_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO3_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR1_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR3_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU10_092514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU1_092414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV10_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV11_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV3_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV4_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV6_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW2_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW6_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX1_112014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX5_112114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY1_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY2_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY8_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY9_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKZ1_122714_HCOFTS\n",
      "removed 0 unknown entries\n",
      "(11600, 3000, 11)\n",
      "(11600,)\n",
      "(11600,)\n",
      "Leaving out mouse number: [ 4.  9. 19. 24. 27. 28.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.31875], 10: [0.2679166666666667], 100: [0.27125], 1000: [0.86125], None: [0.8716666666666667]}\n",
      "Leaving out mouse number: [ 5. 10. 13. 15. 20. 25.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.31875, 0.2504166666666667], 10: [0.2679166666666667, 0.46375], 100: [0.27125, 0.36125], 1000: [0.86125, 0.8520833333333333], None: [0.8716666666666667, 0.87875]}\n",
      "Leaving out mouse number: [ 1.  6. 11. 16. 21. 26.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.31875, 0.2504166666666667, 0.34041666666666665], 10: [0.2679166666666667, 0.46375, 0.4075], 100: [0.27125, 0.36125, 0.2529166666666667], 1000: [0.86125, 0.8520833333333333, 0.8241666666666667], None: [0.8716666666666667, 0.87875, 0.9025]}\n",
      "Leaving out mouse number: [ 0.  2.  7. 12. 17. 22.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.31875, 0.2504166666666667, 0.34041666666666665, 0.49416666666666664], 10: [0.2679166666666667, 0.46375, 0.4075, 0.4625], 100: [0.27125, 0.36125, 0.2529166666666667, 0.685], 1000: [0.86125, 0.8520833333333333, 0.8241666666666667, 0.8854166666666666], None: [0.8716666666666667, 0.87875, 0.9025, 0.9054166666666666]}\n",
      "Leaving out mouse number: [ 3.  8. 14. 18. 23.]\n",
      "9600\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 30\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.31875, 0.2504166666666667, 0.34041666666666665, 0.49416666666666664, 0.257], 10: [0.2679166666666667, 0.46375, 0.4075, 0.4625, 0.25], 100: [0.27125, 0.36125, 0.2529166666666667, 0.685, 0.25], 1000: [0.86125, 0.8520833333333333, 0.8241666666666667, 0.8854166666666666, 0.8775], None: [0.8716666666666667, 0.87875, 0.9025, 0.9054166666666666, 0.907]}\n",
      "{1: 0.33214999999999995, 10: 0.3703333333333333, 100: 0.36408333333333337, 1000: 0.8600833333333334, None: 0.8930666666666667}\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"Mouse_Training_Data\", \"Windowed_Data\", \"\")\n",
    "datasets_list=[]\n",
    "print('Loading Data')\n",
    "f=open(os.path.join(\"training_names.txt\"),'r')\n",
    "lines = f.readlines()\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "groups = []\n",
    "index = 0\n",
    "for line in lines:\n",
    "    recordName=line.strip()\n",
    "    print('Processing', recordName)\n",
    "    data_file=root+recordName+os.sep+recordName\n",
    "    d = Downstream_Dataset(path=data_file)\n",
    "    x_vals.append(d.data)\n",
    "    y_vals.append(d.labels)\n",
    "    groups.append(np.ones(len(d.labels))*index)\n",
    "    index+=1\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n",
    "x_vals = np.vstack(x_vals)\n",
    "y_vals = np.concatenate(y_vals, axis=0)\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "print(x_vals.shape)\n",
    "print(y_vals.shape)\n",
    "print(groups.shape)\n",
    "\n",
    "\n",
    "# logo = LeaveOneGroupOut()\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "# logo.get_n_splits(x_vals, y_vals, groups)\n",
    "kfold.get_n_splits(x_vals, y_vals, groups)\n",
    "\n",
    "result_dict = {}\n",
    "# dtype=torch.int32\n",
    "for train_index, test_index in kfold.split(x_vals, y_vals, groups):\n",
    "    unique = np.unique(groups[test_index])\n",
    "    print(\"Leaving out mouse number:\", unique)\n",
    "    training_set = TensorDataset(torch.tensor(x_vals[train_index], dtype=torch.float), torch.tensor(y_vals[train_index], dtype=torch.long))\n",
    "    test_set = TensorDataset(torch.tensor(x_vals[test_index], dtype=torch.float), torch.tensor(y_vals[test_index], dtype=torch.long))\n",
    "    print(len(training_set))\n",
    "    smallest_class = smallest_class_len(training_set, 3)\n",
    "    num_samples=[]\n",
    "    temp=1\n",
    "    while temp < smallest_class:\n",
    "        num_samples.append(temp)\n",
    "        temp*=10\n",
    "    num_samples.append(None)\n",
    "    accuracy, balanced_accuracy = train_different_classes(\"full_supervision\", training_set, test_set, 100, num_samples)\n",
    "    for num_pos, acc in zip(num_samples, accuracy):\n",
    "        if num_pos not in result_dict:\n",
    "            result_dict[num_pos] = []\n",
    "        result_dict[num_pos].append(acc)\n",
    "    print(result_dict)\n",
    "    \n",
    "for k in result_dict:\n",
    "    result_dict[k] = np.mean(result_dict[k])\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "{1: 0.39258333333333334, 10: 0.36705, 100: 0.2986666666666667, 1000: 0.8434833333333334, None: 0.8944333333333333}\n",
    "{1: 0.2754666666666667, 10: 0.2736166666666667, 100: 0.40263333333333334, 1000: 0.8560833333333333, None: 0.8961833333333333}\n",
    "{1: 0.28291666666666665, 10: 0.31415000000000004, 100: 0.3532, 1000: 0.8490500000000001, None: 0.8926166666666667}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3358833333333333, 0.35051111111111116, 0.37330555555555556, 0.849538888888889, 0.8944111111111112]\n"
     ]
    }
   ],
   "source": [
    "trial1= [0.39258333333333334, 0.36705, 0.36408333333333337, 0.8434833333333334, 0.8944333333333333]\n",
    "trial2=[0.33214999999999995, 0.3703333333333333, 0.40263333333333334, 0.8560833333333333, 0.8961833333333333]\n",
    "trial3= [0.28291666666666665, 0.31415000000000004, 0.3532, 0.8490500000000001, 0.8926166666666667]\n",
    "avg=[]\n",
    "for i in range(len(trial1)):\n",
    "    avg.append((trial1[i]+trial2[i]+trial3[i])/3)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666]\n",
      "10\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888]\n",
      "None\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888, 0.8611111111111112]\n"
     ]
    }
   ],
   "source": [
    "RP_vals = train_different_classes(\"RP_stagernet.pth\", training_set, validation_set, 100, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{1: 0.41169696969696973, 10: 0.4972234848484849, 100: 0.6805530303030303, 1000: 0.854409090909091, None: 0.9312083333333334}\n",
    "\n",
    "[0.41169696969696973, 0.4972234848484849, 0.6805530303030303, 0.854409090909091, 0.9312083333333334]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
