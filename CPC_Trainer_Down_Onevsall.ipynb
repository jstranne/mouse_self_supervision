{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Jason Stranne\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from RP_Downstream_Trainer import DownstreamNet, Downstream_Dataset, print_class_counts, num_correct, reduce_dataset_size\n",
    "from RP_Downstream_Trainer import smallest_class_len, restrict_training_size_per_class, train_end_to_end\n",
    "sys.path.insert(0, '..')\n",
    "from Stager_net_pratice import StagerNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GroupKFold\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_classes(model_path, tset, vset, epochs, sample_list):\n",
    "    outList=[]\n",
    "    balanced_acc_out=[]\n",
    "    for i in sample_list:\n",
    "        # print(i)\n",
    "        acc, balanced_acc = train_end_to_end(model_path, tset, vset, i, epochs, 3)\n",
    "        outList.append(acc)\n",
    "        balanced_acc_out.append(balanced_acc)\n",
    "    return outList, balanced_acc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"CPC_stagernet_16.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Processing MouseCKA1_030515_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKB9_022715_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL1_062514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL5_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL7_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN1_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN2_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN3_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO1_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO2_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO3_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR1_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR3_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU10_092514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU1_092414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV10_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV11_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV3_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV4_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV6_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW2_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW6_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX1_112014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX5_112114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY1_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY2_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY8_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY9_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKZ1_122714_HCOFTS\n",
      "removed 0 unknown entries\n",
      "(11600, 3000, 11)\n",
      "(11600,)\n",
      "(11600,)\n",
      "Leaving out mouse number: [ 4.  9. 19. 24. 27. 28.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.5254166666666666], 10: [0.7816666666666666], 100: [0.8291666666666667], 1000: [0.8716666666666667], None: [0.87]}\n",
      "Leaving out mouse number: [ 5. 10. 13. 15. 20. 25.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.5254166666666666, 0.6529166666666667], 10: [0.7816666666666666, 0.75125], 100: [0.8291666666666667, 0.78], 1000: [0.8716666666666667, 0.8145833333333333], None: [0.87, 0.8470833333333333]}\n",
      "Leaving out mouse number: [ 1.  6. 11. 16. 21. 26.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.5254166666666666, 0.6529166666666667, 0.53375], 10: [0.7816666666666666, 0.75125, 0.33166666666666667], 100: [0.8291666666666667, 0.78, 0.82], 1000: [0.8716666666666667, 0.8145833333333333, 0.84375], None: [0.87, 0.8470833333333333, 0.8625]}\n",
      "Leaving out mouse number: [ 0.  2.  7. 12. 17. 22.]\n",
      "9200\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 29\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.5254166666666666, 0.6529166666666667, 0.53375, 0.42541666666666667], 10: [0.7816666666666666, 0.75125, 0.33166666666666667, 0.84], 100: [0.8291666666666667, 0.78, 0.82, 0.8191666666666667], 1000: [0.8716666666666667, 0.8145833333333333, 0.84375, 0.8575], None: [0.87, 0.8470833333333333, 0.8625, 0.8791666666666667]}\n",
      "Leaving out mouse number: [ 3.  8. 14. 18. 23.]\n",
      "9600\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 30\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.5254166666666666, 0.6529166666666667, 0.53375, 0.42541666666666667, 0.74], 10: [0.7816666666666666, 0.75125, 0.33166666666666667, 0.84, 0.7865], 100: [0.8291666666666667, 0.78, 0.82, 0.8191666666666667, 0.505], 1000: [0.8716666666666667, 0.8145833333333333, 0.84375, 0.8575, 0.875], None: [0.87, 0.8470833333333333, 0.8625, 0.8791666666666667, 0.892]}\n",
      "{1: 0.5754999999999999, 10: 0.6982166666666666, 100: 0.7506666666666667, 1000: 0.8525, None: 0.8701500000000001}\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"Mouse_Training_Data\", \"Windowed_Data\", \"\")\n",
    "datasets_list=[]\n",
    "print('Loading Data')\n",
    "f=open(os.path.join(\"training_names.txt\"),'r')\n",
    "lines = f.readlines()\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "groups = []\n",
    "index = 0\n",
    "for line in lines:\n",
    "    recordName=line.strip()\n",
    "    print('Processing', recordName)\n",
    "    data_file=root+recordName+os.sep+recordName\n",
    "    d = Downstream_Dataset(path=data_file)\n",
    "    x_vals.append(d.data)\n",
    "    y_vals.append(d.labels)\n",
    "    groups.append(np.ones(len(d.labels))*index)\n",
    "    index+=1\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n",
    "x_vals = np.vstack(x_vals)\n",
    "y_vals = np.concatenate(y_vals, axis=0)\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "print(x_vals.shape)\n",
    "print(y_vals.shape)\n",
    "print(groups.shape)\n",
    "\n",
    "\n",
    "# logo = LeaveOneGroupOut()\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "# logo.get_n_splits(x_vals, y_vals, groups)\n",
    "kfold.get_n_splits(x_vals, y_vals, groups)\n",
    "\n",
    "result_dict = {}\n",
    "# dtype=torch.int32\n",
    "for train_index, test_index in kfold.split(x_vals, y_vals, groups):\n",
    "    unique = np.unique(groups[test_index])\n",
    "    # group_num = groups[test_index][0]\n",
    "    print(\"Leaving out mouse number:\", unique)\n",
    "    training_set = TensorDataset(torch.tensor(x_vals[train_index], dtype=torch.float), torch.tensor(y_vals[train_index], dtype=torch.long))\n",
    "    test_set = TensorDataset(torch.tensor(x_vals[test_index], dtype=torch.float), torch.tensor(y_vals[test_index], dtype=torch.long))\n",
    "    print(len(training_set))\n",
    "    smallest_class = smallest_class_len(training_set, 3)\n",
    "    num_samples=[]\n",
    "    temp=1\n",
    "    while temp < smallest_class:\n",
    "        num_samples.append(temp)\n",
    "        temp*=10\n",
    "    num_samples.append(None)\n",
    "    accuracy, balanced_accuracy = train_different_classes(model_path, training_set, test_set, 100, num_samples)\n",
    "    for num_pos, acc in zip(num_samples, accuracy):\n",
    "        if num_pos not in result_dict:\n",
    "            result_dict[num_pos] = []\n",
    "        result_dict[num_pos].append(acc)\n",
    "    print(result_dict)\n",
    "    \n",
    "for k in result_dict:\n",
    "    result_dict[k] = np.mean(result_dict[k])\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "{1: 0.40280000000000005, 10: 0.6200333333333333, 100: 0.7457166666666667, 1000: 0.8544499999999999, None: 0.8680333333333333}\n",
    "{1: 0.5320666666666667, 10: 0.6231666666666666, 100: 0.8195333333333334, 1000: 0.8502166666666666, None: 0.8702500000000001}\n",
    "{1: 0.5754999999999999, 10: 0.6982166666666666, 100: 0.7506666666666667, 1000: 0.8525, None: 0.8701500000000001}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5034555555555555, 0.6471388888888888, 0.7719722222222223, 0.8523888888888888, 0.8694777777777779]\n"
     ]
    }
   ],
   "source": [
    "trial1=[0.40280000000000005, 0.6200333333333333, 0.7457166666666667, 0.8544499999999999, 0.8680333333333333]\n",
    "trial2=[0.5320666666666667, 0.6231666666666666, 0.8195333333333334,  0.8502166666666666,0.8702500000000001]\n",
    "trial3=[0.5754999999999999, 0.6982166666666666, 0.7506666666666667, 0.8525, 0.8701500000000001]\n",
    "avg=[]\n",
    "for i in range(len(trial1)):\n",
    "    avg.append((trial1[i]+trial2[i]+trial3[i])/3)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666]\n",
      "10\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888]\n",
      "None\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888, 0.8611111111111112]\n"
     ]
    }
   ],
   "source": [
    "RP_vals = train_different_classes(\"RP_stagernet.pth\", training_set, validation_set, 100, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{1: 0.5484583333333334, 10: 0.6462386363636364, 100: 0.6729166666666668, 1000: 0.8481856060606059, None: 0.8696249999999999}\n",
    "\n",
    "[0.5484583333333334, 0.6462386363636364, 0.6729166666666668, 0.8481856060606059, 0.8696249999999999]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
