{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Jason Stranne\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from RP_Downstream_Trainer import DownstreamNet, Downstream_Dataset, print_class_counts, num_correct, reduce_dataset_size\n",
    "from RP_Downstream_Trainer import smallest_class_len, restrict_training_size_per_class, train_end_to_end\n",
    "sys.path.insert(0, '..')\n",
    "from Stager_net_pratice import StagerNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GroupKFold\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_classes(model_path, tset, vset, epochs, sample_list):\n",
    "    outList=[]\n",
    "    balanced_acc_out=[]\n",
    "    for i in sample_list:\n",
    "        # print(i)\n",
    "        acc, balanced_acc = train_end_to_end(model_path, tset, vset, i, epochs, 3)\n",
    "        outList.append(acc)\n",
    "        balanced_acc_out.append(balanced_acc)\n",
    "    return outList, balanced_acc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"CPC_stagernet_16.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Processing MouseCKA1_030515_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKA1_030615_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL1_062514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKB9_022715_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKB9_022815_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL7_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL5_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL5_070114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKL7_070114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN1_063014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN2_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN3_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN3_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO1_070214_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN2_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO1_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO2_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKN1_070114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO2_070414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO3_070314_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKO3_070414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR1_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR1_082614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR3_082514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU1_092414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU1_092514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU10_092514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKR3_082614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKU10_092614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV3_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV3_101114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV4_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV4_101114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV10_101514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV6_101114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV6_101014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV10_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV11_101414_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKV11_101514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW6_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW2_111114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW6_111114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKW2_111014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX1_112114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX1_112014_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKX5_112114_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY1_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY1_120614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY2_120514_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY9_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY2_120614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY8_112614_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY8_112714_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKY9_112714_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKZ1_122814_HCOFTS\n",
      "removed 0 unknown entries\n",
      "Processing MouseCKZ1_122714_HCOFTS\n",
      "removed 0 unknown entries\n",
      "(22400, 3000, 11)\n",
      "(22400,)\n",
      "(22400,)\n",
      "Leaving out mouse number: [ 0.  2.  7. 12. 17. 22. 34. 39. 42. 44. 49. 55.]\n",
      "17600\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 55\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.20979166666666665], 10: [0.524375], 100: [0.19708333333333333], 1000: [0.8547916666666666], None: [0.880625]}\n",
      "Leaving out mouse number: [ 1.  6. 11. 16. 21. 33. 38. 43. 48. 53. 54.]\n",
      "18000\n",
      "len of the dataloader is: 1\n",
      "Start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 57\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.20979166666666665, 0.7297727272727272], 10: [0.524375, 0.7397727272727272], 100: [0.19708333333333333, 0.8047727272727273], 1000: [0.8547916666666666, 0.8413636363636363], None: [0.880625, 0.8613636363636363]}\n",
      "Leaving out mouse number: [ 5. 10. 15. 20. 25. 26. 32. 37. 41. 47. 52.]\n",
      "18000\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 57\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.20979166666666665, 0.7297727272727272, 0.5184090909090909], 10: [0.524375, 0.7397727272727272, 0.4125], 100: [0.19708333333333333, 0.8047727272727273, 0.7806818181818181], 1000: [0.8547916666666666, 0.8413636363636363, 0.8340909090909091], None: [0.880625, 0.8613636363636363, 0.8611363636363636]}\n",
      "Leaving out mouse number: [ 4.  9. 14. 19. 24. 27. 29. 31. 36. 46. 51.]\n",
      "18000\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 57\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.20979166666666665, 0.7297727272727272, 0.5184090909090909, 0.7263636363636363], 10: [0.524375, 0.7397727272727272, 0.4125, 0.7959090909090909], 100: [0.19708333333333333, 0.8047727272727273, 0.7806818181818181, 0.8127272727272727], 1000: [0.8547916666666666, 0.8413636363636363, 0.8340909090909091, 0.8586363636363636], None: [0.880625, 0.8613636363636363, 0.8611363636363636, 0.8695454545454545]}\n",
      "Leaving out mouse number: [ 3.  8. 13. 18. 23. 28. 30. 35. 40. 45. 50.]\n",
      "18000\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "len of the dataloader is: 2\n",
      "Start Training\n",
      "len of the dataloader is: 12\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "len of the dataloader is: 57\n",
      "Start Training\n",
      "EARLY STOPPING\n",
      "{1: [0.20979166666666665, 0.7297727272727272, 0.5184090909090909, 0.7263636363636363, 0.5579545454545455], 10: [0.524375, 0.7397727272727272, 0.4125, 0.7959090909090909, 0.7586363636363637], 100: [0.19708333333333333, 0.8047727272727273, 0.7806818181818181, 0.8127272727272727, 0.7693181818181818], 1000: [0.8547916666666666, 0.8413636363636363, 0.8340909090909091, 0.8586363636363636, 0.8520454545454546], None: [0.880625, 0.8613636363636363, 0.8611363636363636, 0.8695454545454545, 0.8754545454545455]}\n",
      "{1: 0.5484583333333334, 10: 0.6462386363636364, 100: 0.6729166666666668, 1000: 0.8481856060606059, None: 0.8696249999999999}\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join(\"Mouse_Training_Data\", \"Windowed_Data\", \"\")\n",
    "datasets_list=[]\n",
    "print('Loading Data')\n",
    "f=open(os.path.join(\"training_names.txt\"),'r')\n",
    "lines = f.readlines()\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "groups = []\n",
    "index = 0\n",
    "for line in lines:\n",
    "    recordName=line.strip()\n",
    "    print('Processing', recordName)\n",
    "    data_file=root+recordName+os.sep+recordName\n",
    "    d = Downstream_Dataset(path=data_file)\n",
    "    x_vals.append(d.data)\n",
    "    y_vals.append(d.labels)\n",
    "    groups.append(np.ones(len(d.labels))*index)\n",
    "    index+=1\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n",
    "x_vals = np.vstack(x_vals)\n",
    "y_vals = np.concatenate(y_vals, axis=0)\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "print(x_vals.shape)\n",
    "print(y_vals.shape)\n",
    "print(groups.shape)\n",
    "\n",
    "\n",
    "# logo = LeaveOneGroupOut()\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "# logo.get_n_splits(x_vals, y_vals, groups)\n",
    "kfold.get_n_splits(x_vals, y_vals, groups)\n",
    "\n",
    "result_dict = {}\n",
    "# dtype=torch.int32\n",
    "for train_index, test_index in kfold.split(x_vals, y_vals, groups):\n",
    "    unique = np.unique(groups[test_index])\n",
    "    # group_num = groups[test_index][0]\n",
    "    print(\"Leaving out mouse number:\", unique)\n",
    "    training_set = TensorDataset(torch.tensor(x_vals[train_index], dtype=torch.float), torch.tensor(y_vals[train_index], dtype=torch.long))\n",
    "    test_set = TensorDataset(torch.tensor(x_vals[test_index], dtype=torch.float), torch.tensor(y_vals[test_index], dtype=torch.long))\n",
    "    print(len(training_set))\n",
    "    smallest_class = smallest_class_len(training_set, 3)\n",
    "    num_samples=[]\n",
    "    temp=1\n",
    "    while temp < smallest_class:\n",
    "        num_samples.append(temp)\n",
    "        temp*=10\n",
    "    num_samples.append(None)\n",
    "    accuracy, balanced_accuracy = train_different_classes(model_path, training_set, test_set, 100, num_samples)\n",
    "    for num_pos, acc in zip(num_samples, accuracy):\n",
    "        if num_pos not in result_dict:\n",
    "            result_dict[num_pos] = []\n",
    "        result_dict[num_pos].append(acc)\n",
    "    print(result_dict)\n",
    "    \n",
    "for k in result_dict:\n",
    "    result_dict[k] = np.mean(result_dict[k])\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666]\n",
      "10\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888]\n",
      "None\n",
      "len of the dataloader is: 1\n",
      "Start Training\n",
      "[0.5416666666666666, 0.8263888888888888, 0.8611111111111112]\n"
     ]
    }
   ],
   "source": [
    "RP_vals = train_different_classes(\"RP_stagernet.pth\", training_set, validation_set, 100, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{1: 0.5484583333333334, 10: 0.6462386363636364, 100: 0.6729166666666668, 1000: 0.8481856060606059, None: 0.8696249999999999}\n",
    "\n",
    "[0.5484583333333334, 0.6462386363636364, 0.6729166666666668, 0.8481856060606059, 0.8696249999999999]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
